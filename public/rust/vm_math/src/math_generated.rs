// automatically generated by the FlatBuffers compiler, do not modify



use std::mem;
use std::cmp::Ordering;

extern crate flatbuffers;
use self::flatbuffers::EndianScalar;

#[allow(unused_imports, dead_code)]
pub mod tech_paws {

  use std::mem;
  use std::cmp::Ordering;

  extern crate flatbuffers;
  use self::flatbuffers::EndianScalar;
#[allow(unused_imports, dead_code)]
pub mod schemes {

  use std::mem;
  use std::cmp::Ordering;

  extern crate flatbuffers;
  use self::flatbuffers::EndianScalar;
#[allow(unused_imports, dead_code)]
pub mod math {

  use std::mem;
  use std::cmp::Ordering;

  extern crate flatbuffers;
  use self::flatbuffers::EndianScalar;

// struct Vec2f, aligned to 4
#[repr(C, align(4))]
#[derive(Clone, Copy, Debug, PartialEq)]
pub struct Vec2f {
  x_: f32,
  y_: f32,
} // pub struct Vec2f
impl flatbuffers::SafeSliceAccess for Vec2f {}
impl<'a> flatbuffers::Follow<'a> for Vec2f {
  type Inner = &'a Vec2f;
  #[inline]
  fn follow(buf: &'a [u8], loc: usize) -> Self::Inner {
    <&'a Vec2f>::follow(buf, loc)
  }
}
impl<'a> flatbuffers::Follow<'a> for &'a Vec2f {
  type Inner = &'a Vec2f;
  #[inline]
  fn follow(buf: &'a [u8], loc: usize) -> Self::Inner {
    flatbuffers::follow_cast_ref::<Vec2f>(buf, loc)
  }
}
impl<'b> flatbuffers::Push for Vec2f {
    type Output = Vec2f;
    #[inline]
    fn push(&self, dst: &mut [u8], _rest: &[u8]) {
        let src = unsafe {
            ::std::slice::from_raw_parts(self as *const Vec2f as *const u8, Self::size())
        };
        dst.copy_from_slice(src);
    }
}
impl<'b> flatbuffers::Push for &'b Vec2f {
    type Output = Vec2f;

    #[inline]
    fn push(&self, dst: &mut [u8], _rest: &[u8]) {
        let src = unsafe {
            ::std::slice::from_raw_parts(*self as *const Vec2f as *const u8, Self::size())
        };
        dst.copy_from_slice(src);
    }
}


impl Vec2f {
  pub fn new<'a>(_x: f32, _y: f32) -> Self {
    Vec2f {
      x_: _x.to_little_endian(),
      y_: _y.to_little_endian(),

    }
  }
  pub fn x<'a>(&'a self) -> f32 {
    self.x_.from_little_endian()
  }
  pub fn y<'a>(&'a self) -> f32 {
    self.y_.from_little_endian()
  }
}

// struct Vec3f, aligned to 4
#[repr(C, align(4))]
#[derive(Clone, Copy, Debug, PartialEq)]
pub struct Vec3f {
  x_: f32,
  y_: f32,
  z_: f32,
} // pub struct Vec3f
impl flatbuffers::SafeSliceAccess for Vec3f {}
impl<'a> flatbuffers::Follow<'a> for Vec3f {
  type Inner = &'a Vec3f;
  #[inline]
  fn follow(buf: &'a [u8], loc: usize) -> Self::Inner {
    <&'a Vec3f>::follow(buf, loc)
  }
}
impl<'a> flatbuffers::Follow<'a> for &'a Vec3f {
  type Inner = &'a Vec3f;
  #[inline]
  fn follow(buf: &'a [u8], loc: usize) -> Self::Inner {
    flatbuffers::follow_cast_ref::<Vec3f>(buf, loc)
  }
}
impl<'b> flatbuffers::Push for Vec3f {
    type Output = Vec3f;
    #[inline]
    fn push(&self, dst: &mut [u8], _rest: &[u8]) {
        let src = unsafe {
            ::std::slice::from_raw_parts(self as *const Vec3f as *const u8, Self::size())
        };
        dst.copy_from_slice(src);
    }
}
impl<'b> flatbuffers::Push for &'b Vec3f {
    type Output = Vec3f;

    #[inline]
    fn push(&self, dst: &mut [u8], _rest: &[u8]) {
        let src = unsafe {
            ::std::slice::from_raw_parts(*self as *const Vec3f as *const u8, Self::size())
        };
        dst.copy_from_slice(src);
    }
}


impl Vec3f {
  pub fn new<'a>(_x: f32, _y: f32, _z: f32) -> Self {
    Vec3f {
      x_: _x.to_little_endian(),
      y_: _y.to_little_endian(),
      z_: _z.to_little_endian(),

    }
  }
  pub fn x<'a>(&'a self) -> f32 {
    self.x_.from_little_endian()
  }
  pub fn y<'a>(&'a self) -> f32 {
    self.y_.from_little_endian()
  }
  pub fn z<'a>(&'a self) -> f32 {
    self.z_.from_little_endian()
  }
}

// struct Vec4f, aligned to 4
#[repr(C, align(4))]
#[derive(Clone, Copy, Debug, PartialEq)]
pub struct Vec4f {
  x_: f32,
  y_: f32,
  z_: f32,
  w_: f32,
} // pub struct Vec4f
impl flatbuffers::SafeSliceAccess for Vec4f {}
impl<'a> flatbuffers::Follow<'a> for Vec4f {
  type Inner = &'a Vec4f;
  #[inline]
  fn follow(buf: &'a [u8], loc: usize) -> Self::Inner {
    <&'a Vec4f>::follow(buf, loc)
  }
}
impl<'a> flatbuffers::Follow<'a> for &'a Vec4f {
  type Inner = &'a Vec4f;
  #[inline]
  fn follow(buf: &'a [u8], loc: usize) -> Self::Inner {
    flatbuffers::follow_cast_ref::<Vec4f>(buf, loc)
  }
}
impl<'b> flatbuffers::Push for Vec4f {
    type Output = Vec4f;
    #[inline]
    fn push(&self, dst: &mut [u8], _rest: &[u8]) {
        let src = unsafe {
            ::std::slice::from_raw_parts(self as *const Vec4f as *const u8, Self::size())
        };
        dst.copy_from_slice(src);
    }
}
impl<'b> flatbuffers::Push for &'b Vec4f {
    type Output = Vec4f;

    #[inline]
    fn push(&self, dst: &mut [u8], _rest: &[u8]) {
        let src = unsafe {
            ::std::slice::from_raw_parts(*self as *const Vec4f as *const u8, Self::size())
        };
        dst.copy_from_slice(src);
    }
}


impl Vec4f {
  pub fn new<'a>(_x: f32, _y: f32, _z: f32, _w: f32) -> Self {
    Vec4f {
      x_: _x.to_little_endian(),
      y_: _y.to_little_endian(),
      z_: _z.to_little_endian(),
      w_: _w.to_little_endian(),

    }
  }
  pub fn x<'a>(&'a self) -> f32 {
    self.x_.from_little_endian()
  }
  pub fn y<'a>(&'a self) -> f32 {
    self.y_.from_little_endian()
  }
  pub fn z<'a>(&'a self) -> f32 {
    self.z_.from_little_endian()
  }
  pub fn w<'a>(&'a self) -> f32 {
    self.w_.from_little_endian()
  }
}

// struct Mat4f, aligned to 4
#[repr(C, align(4))]
#[derive(Clone, Copy, Debug, PartialEq)]
pub struct Mat4f {
  c1_: Vec4f,
  c2_: Vec4f,
  c3_: Vec4f,
  c4_: Vec4f,
} // pub struct Mat4f
impl flatbuffers::SafeSliceAccess for Mat4f {}
impl<'a> flatbuffers::Follow<'a> for Mat4f {
  type Inner = &'a Mat4f;
  #[inline]
  fn follow(buf: &'a [u8], loc: usize) -> Self::Inner {
    <&'a Mat4f>::follow(buf, loc)
  }
}
impl<'a> flatbuffers::Follow<'a> for &'a Mat4f {
  type Inner = &'a Mat4f;
  #[inline]
  fn follow(buf: &'a [u8], loc: usize) -> Self::Inner {
    flatbuffers::follow_cast_ref::<Mat4f>(buf, loc)
  }
}
impl<'b> flatbuffers::Push for Mat4f {
    type Output = Mat4f;
    #[inline]
    fn push(&self, dst: &mut [u8], _rest: &[u8]) {
        let src = unsafe {
            ::std::slice::from_raw_parts(self as *const Mat4f as *const u8, Self::size())
        };
        dst.copy_from_slice(src);
    }
}
impl<'b> flatbuffers::Push for &'b Mat4f {
    type Output = Mat4f;

    #[inline]
    fn push(&self, dst: &mut [u8], _rest: &[u8]) {
        let src = unsafe {
            ::std::slice::from_raw_parts(*self as *const Mat4f as *const u8, Self::size())
        };
        dst.copy_from_slice(src);
    }
}


impl Mat4f {
  pub fn new<'a>(_c1: &'a Vec4f, _c2: &'a Vec4f, _c3: &'a Vec4f, _c4: &'a Vec4f) -> Self {
    Mat4f {
      c1_: *_c1,
      c2_: *_c2,
      c3_: *_c3,
      c4_: *_c4,

    }
  }
  pub fn c1<'a>(&'a self) -> &'a Vec4f {
    &self.c1_
  }
  pub fn c2<'a>(&'a self) -> &'a Vec4f {
    &self.c2_
  }
  pub fn c3<'a>(&'a self) -> &'a Vec4f {
    &self.c3_
  }
  pub fn c4<'a>(&'a self) -> &'a Vec4f {
    &self.c4_
  }
}

}  // pub mod Math
}  // pub mod Schemes
}  // pub mod TechPaws

